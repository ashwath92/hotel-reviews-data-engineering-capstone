{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                     .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:2.7.0\")\\\n",
    "                     .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Hotel_Address: string (nullable = true)\n",
      " |-- Additional_Number_of_Scoring: integer (nullable = true)\n",
      " |-- Review_Date: string (nullable = true)\n",
      " |-- Average_Score: double (nullable = true)\n",
      " |-- Hotel_Name: string (nullable = true)\n",
      " |-- Reviewer_Nationality: string (nullable = true)\n",
      " |-- Negative_Review: string (nullable = true)\n",
      " |-- Review_Total_Negative_Word_Counts: integer (nullable = true)\n",
      " |-- Total_Number_of_Reviews: integer (nullable = true)\n",
      " |-- Positive_Review: string (nullable = true)\n",
      " |-- Review_Total_Positive_Word_Counts: integer (nullable = true)\n",
      " |-- Total_Number_of_Reviews_Reviewer_Has_Given: integer (nullable = true)\n",
      " |-- Reviewer_Score: double (nullable = true)\n",
      " |-- Tags: string (nullable = true)\n",
      " |-- days_since_review: string (nullable = true)\n",
      " |-- lat: string (nullable = true)\n",
      " |-- lng: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in the data here\n",
    "df_hotel_reviews = spark.read.csv('../Data/Original/Hotel_Reviews.csv', header=True, inferSchema=True)\n",
    "df_hotel_reviews.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(515738, 17)\n"
     ]
    }
   ],
   "source": [
    "print((df_hotel_reviews.count(), len(df_hotel_reviews.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hotel nam e'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.parsing import preprocessing\n",
    "text = preprocessing.strip_multiple_whitespaces(preprocessing.strip_punctuation('Hotel-nam$e  '))\n",
    "text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_Address</th>\n",
       "      <th>Additional_Number_of_Scoring</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Reviewer_Nationality</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Review_Total_Negative_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews</th>\n",
       "      <th>Positive_Review</th>\n",
       "      <th>Review_Total_Positive_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>days_since_review</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>8/3/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Russia</td>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>397</td>\n",
       "      <td>1403</td>\n",
       "      <td>Only the park outside of the hotel was beauti...</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "      <td>0 days</td>\n",
       "      <td>52.3605759</td>\n",
       "      <td>4.9159683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>8/3/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1403</td>\n",
       "      <td>No real complaints the hotel was great great ...</td>\n",
       "      <td>105</td>\n",
       "      <td>7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "      <td>0 days</td>\n",
       "      <td>52.3605759</td>\n",
       "      <td>4.9159683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/31/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>42</td>\n",
       "      <td>1403</td>\n",
       "      <td>Location was good and staff were ok It is cut...</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>[' Leisure trip ', ' Family with young childre...</td>\n",
       "      <td>3 days</td>\n",
       "      <td>52.3605759</td>\n",
       "      <td>4.9159683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/31/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "      <td>210</td>\n",
       "      <td>1403</td>\n",
       "      <td>Great location in nice surroundings the bar a...</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[' Leisure trip ', ' Solo traveler ', ' Duplex...</td>\n",
       "      <td>3 days</td>\n",
       "      <td>52.3605759</td>\n",
       "      <td>4.9159683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/24/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "      <td>140</td>\n",
       "      <td>1403</td>\n",
       "      <td>Amazing location and building Romantic setting</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Suite ', ' St...</td>\n",
       "      <td>10 days</td>\n",
       "      <td>52.3605759</td>\n",
       "      <td>4.9159683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Hotel_Address  \\\n",
       "0   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "1   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "2   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "3   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "4   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "\n",
       "   Additional_Number_of_Scoring Review_Date  Average_Score   Hotel_Name  \\\n",
       "0                           194    8/3/2017            7.7  Hotel Arena   \n",
       "1                           194    8/3/2017            7.7  Hotel Arena   \n",
       "2                           194   7/31/2017            7.7  Hotel Arena   \n",
       "3                           194   7/31/2017            7.7  Hotel Arena   \n",
       "4                           194   7/24/2017            7.7  Hotel Arena   \n",
       "\n",
       "  Reviewer_Nationality                                    Negative_Review  \\\n",
       "0              Russia    I am so angry that i made this post available...   \n",
       "1             Ireland                                         No Negative   \n",
       "2           Australia    Rooms are nice but for elderly a bit difficul...   \n",
       "3      United Kingdom    My room was dirty and I was afraid to walk ba...   \n",
       "4         New Zealand    You When I booked with your company on line y...   \n",
       "\n",
       "   Review_Total_Negative_Word_Counts  Total_Number_of_Reviews  \\\n",
       "0                                397                     1403   \n",
       "1                                  0                     1403   \n",
       "2                                 42                     1403   \n",
       "3                                210                     1403   \n",
       "4                                140                     1403   \n",
       "\n",
       "                                     Positive_Review  \\\n",
       "0   Only the park outside of the hotel was beauti...   \n",
       "1   No real complaints the hotel was great great ...   \n",
       "2   Location was good and staff were ok It is cut...   \n",
       "3   Great location in nice surroundings the bar a...   \n",
       "4    Amazing location and building Romantic setting    \n",
       "\n",
       "   Review_Total_Positive_Word_Counts  \\\n",
       "0                                 11   \n",
       "1                                105   \n",
       "2                                 21   \n",
       "3                                 26   \n",
       "4                                  8   \n",
       "\n",
       "   Total_Number_of_Reviews_Reviewer_Has_Given  Reviewer_Score  \\\n",
       "0                                           7             2.9   \n",
       "1                                           7             7.5   \n",
       "2                                           9             7.1   \n",
       "3                                           1             3.8   \n",
       "4                                           3             6.7   \n",
       "\n",
       "                                                Tags days_since_review  \\\n",
       "0  [' Leisure trip ', ' Couple ', ' Duplex Double...            0 days   \n",
       "1  [' Leisure trip ', ' Couple ', ' Duplex Double...            0 days   \n",
       "2  [' Leisure trip ', ' Family with young childre...            3 days   \n",
       "3  [' Leisure trip ', ' Solo traveler ', ' Duplex...            3 days   \n",
       "4  [' Leisure trip ', ' Couple ', ' Suite ', ' St...           10 days   \n",
       "\n",
       "          lat        lng  \n",
       "0  52.3605759  4.9159683  \n",
       "1  52.3605759  4.9159683  \n",
       "2  52.3605759  4.9159683  \n",
       "3  52.3605759  4.9159683  \n",
       "4  52.3605759  4.9159683  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hotel_reviews.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dist_hotel_columns = ['Hotel_Name', 'Hotel_Address', 'lat', 'lng']\n",
    "df_distinct_hotels = df_hotel_reviews.dropDuplicates(subset=dist_hotel_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1494, 17)\n"
     ]
    }
   ],
   "source": [
    "print((df_distinct_hotels.count(), len(df_distinct_hotels.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "There are therefore only 1494 unique hotels, even though there are more than half a million reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_Address</th>\n",
       "      <th>Additional_Number_of_Scoring</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Reviewer_Nationality</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Review_Total_Negative_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews</th>\n",
       "      <th>Positive_Review</th>\n",
       "      <th>Review_Total_Positive_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>days_since_review</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Savoyenstra e 2 16 Ottakring 1160 Vienna Austria</td>\n",
       "      <td>86</td>\n",
       "      <td>7/31/2017</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Austria Trend Hotel Schloss Wilhelminenberg Wien</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Although the building looks majestic on the o...</td>\n",
       "      <td>79</td>\n",
       "      <td>1558</td>\n",
       "      <td>Excellent location with spectacular view over...</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>[' Leisure trip ', ' Group ', ' Classic Room '...</td>\n",
       "      <td>3 days</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Epping Forest 30 Oak Hill London IG8 9NY Unite...</td>\n",
       "      <td>193</td>\n",
       "      <td>8/2/2017</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Best Western PLUS Epping Forest</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Bed seemed small for a double Room a bit gloo...</td>\n",
       "      <td>24</td>\n",
       "      <td>587</td>\n",
       "      <td>Easy check in Friendly staff Reasonably price...</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>7.9</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Standard Doub...</td>\n",
       "      <td>1 days</td>\n",
       "      <td>51.603207</td>\n",
       "      <td>0.010607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Passeig de Gr cia 29 Eixample 08007 Barcelona ...</td>\n",
       "      <td>172</td>\n",
       "      <td>7/30/2017</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Eurostars Bcn Design</td>\n",
       "      <td>Australia</td>\n",
       "      <td>The hallways feel like your in a hostel and t...</td>\n",
       "      <td>69</td>\n",
       "      <td>1601</td>\n",
       "      <td>Location and great black out curtains which r...</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>7.1</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Basic Double ...</td>\n",
       "      <td>4 days</td>\n",
       "      <td>41.3907208</td>\n",
       "      <td>2.1660732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Hotel_Address  \\\n",
       "0   Savoyenstra e 2 16 Ottakring 1160 Vienna Austria   \n",
       "1  Epping Forest 30 Oak Hill London IG8 9NY Unite...   \n",
       "2  Passeig de Gr cia 29 Eixample 08007 Barcelona ...   \n",
       "\n",
       "   Additional_Number_of_Scoring Review_Date  Average_Score  \\\n",
       "0                            86   7/31/2017            8.3   \n",
       "1                           193    8/2/2017            7.5   \n",
       "2                           172   7/30/2017            8.3   \n",
       "\n",
       "                                         Hotel_Name Reviewer_Nationality  \\\n",
       "0  Austria Trend Hotel Schloss Wilhelminenberg Wien         Netherlands    \n",
       "1                   Best Western PLUS Epping Forest      United Kingdom    \n",
       "2                              Eurostars Bcn Design           Australia    \n",
       "\n",
       "                                     Negative_Review  \\\n",
       "0   Although the building looks majestic on the o...   \n",
       "1   Bed seemed small for a double Room a bit gloo...   \n",
       "2   The hallways feel like your in a hostel and t...   \n",
       "\n",
       "   Review_Total_Negative_Word_Counts  Total_Number_of_Reviews  \\\n",
       "0                                 79                     1558   \n",
       "1                                 24                      587   \n",
       "2                                 69                     1601   \n",
       "\n",
       "                                     Positive_Review  \\\n",
       "0   Excellent location with spectacular view over...   \n",
       "1   Easy check in Friendly staff Reasonably price...   \n",
       "2   Location and great black out curtains which r...   \n",
       "\n",
       "   Review_Total_Positive_Word_Counts  \\\n",
       "0                                 55   \n",
       "1                                 24   \n",
       "2                                 17   \n",
       "\n",
       "   Total_Number_of_Reviews_Reviewer_Has_Given  Reviewer_Score  \\\n",
       "0                                           3             8.3   \n",
       "1                                           3             7.9   \n",
       "2                                          26             7.1   \n",
       "\n",
       "                                                Tags days_since_review  \\\n",
       "0  [' Leisure trip ', ' Group ', ' Classic Room '...            3 days   \n",
       "1  [' Leisure trip ', ' Couple ', ' Standard Doub...            1 days   \n",
       "2  [' Leisure trip ', ' Couple ', ' Basic Double ...            4 days   \n",
       "\n",
       "          lat        lng  \n",
       "0          NA         NA  \n",
       "1   51.603207   0.010607  \n",
       "2  41.3907208  2.1660732  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_distinct_hotels.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Get the (distinct) countries which the hotels are located in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_last_word(address):\n",
    "    \"\"\" Gets the last word of the string 'address'\"\"\"\n",
    "    return address.split()[-1]\n",
    "\n",
    "udf_get_last_word = F.udf(get_last_word, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_distinct_countries = df_distinct_hotels.withColumn('country', udf_get_last_word(\"Hotel_Address\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|    country|\n",
      "+-----------+\n",
      "|     France|\n",
      "|      Italy|\n",
      "|      Spain|\n",
      "|    Kingdom|\n",
      "|    Austria|\n",
      "|Netherlands|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_distinct_countries.select('country').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Get the number of nationalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hotel_reviews.select('Reviewer_Nationality').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "So, we see that there are hotels from 6 countries, but reviewers from 227 countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "list_of_reviewer_nationalities = df_hotel_reviews.select('Reviewer_Nationality').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "reviewer_nationalities = [row.__getitem__('Reviewer_Nationality') for row in list_of_reviewer_nationalities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Montenegro ',\n",
       " ' Saint Vincent Grenadines ',\n",
       " ' Northern Mariana Islands ',\n",
       " ' Gibraltar ',\n",
       " ' Syria ',\n",
       " ' Czech Republic ',\n",
       " ' Guyana ',\n",
       " ' New Zealand ',\n",
       " ' Austria ',\n",
       " ' Bulgaria ',\n",
       " ' Saint Martin ',\n",
       " ' Argentina ',\n",
       " ' Eritrea ',\n",
       " ' United States of America ',\n",
       " ' Azerbaijan ',\n",
       " ' Fiji ',\n",
       " ' Spain ',\n",
       " ' Zambia ',\n",
       " ' Laos ',\n",
       " ' Australia ',\n",
       " ' South Sudan ',\n",
       " ' Ecuador ',\n",
       " ' Yemen ',\n",
       " ' Suriname ',\n",
       " ' Svalbard Jan Mayen ',\n",
       " ' Turkey ',\n",
       " ' American Samoa ',\n",
       " ' Guernsey ',\n",
       " ' Bosnia and Herzegovina ',\n",
       " ' Ghana ',\n",
       " ' Vanuatu ',\n",
       " ' U S Virgin Islands ',\n",
       " ' United Kingdom ',\n",
       " ' Rwanda ',\n",
       " ' Gambia ',\n",
       " ' Liechtenstein ',\n",
       " ' Kuwait ',\n",
       " ' Comoros ',\n",
       " ' Mauritius ',\n",
       " ' Kosovo ',\n",
       " ' Senegal ',\n",
       " ' St Pierre and Miquelon ',\n",
       " ' Tajikistan ',\n",
       " ' Luxembourg ',\n",
       " ' Bolivia ',\n",
       " ' Pakistan ',\n",
       " ' Sudan ',\n",
       " ' Madagascar ',\n",
       " ' Latvia ',\n",
       " ' Brunei ',\n",
       " ' Libya ',\n",
       " ' Malawi ',\n",
       " ' Somalia ',\n",
       " ' Palau ',\n",
       " ' Canada ',\n",
       " ' Tunisia ',\n",
       " ' Djibouti ',\n",
       " ' Bermuda ',\n",
       " ' Central Africa Republic ',\n",
       " ' Bahamas ',\n",
       " ' Andorra ',\n",
       " ' Guadeloupe ',\n",
       " ' Swaziland ',\n",
       " ' Cyprus ',\n",
       " ' Cape Verde ',\n",
       " ' Iran ',\n",
       " ' Honduras ',\n",
       " ' Indonesia ',\n",
       " ' Cameroon ',\n",
       " ' Haiti ',\n",
       " ' Tuvalu ',\n",
       " ' Cocos K I ',\n",
       " ' Armenia ',\n",
       " ' Turkmenistan ',\n",
       " ' Sweden ',\n",
       " ' Sri Lanka ',\n",
       " ' Kazakhstan ',\n",
       " ' Jamaica ',\n",
       " ' Bhutan ',\n",
       " ' Cook Islands ',\n",
       " ' Serbia ',\n",
       " ' France ',\n",
       " ' Cambodia ',\n",
       " ' Ireland ',\n",
       " ' Morocco ',\n",
       " ' Vietnam ',\n",
       " ' Antigua Barbuda ',\n",
       " ' Malaysia ',\n",
       " ' Lebanon ',\n",
       " ' Samoa ',\n",
       " ' Guatemala ',\n",
       " ' Egypt ',\n",
       " ' Bahrain ',\n",
       " ' Russia ',\n",
       " ' Seychelles ',\n",
       " ' Italy ',\n",
       " ' Bangladesh ',\n",
       " ' Democratic Republic of the Congo ',\n",
       " ' Trinidad and Tobago ',\n",
       " ' Martinique ',\n",
       " ' Iraq ',\n",
       " ' Afghanistan ',\n",
       " ' Wallis and Futuna ',\n",
       " ' Philippines ',\n",
       " ' Hungary ',\n",
       " ' Greece ',\n",
       " ' Uganda ',\n",
       " ' Sierra Leone ',\n",
       " ' Mongolia ',\n",
       " ' United Arab Emirates ',\n",
       " ' Albania ',\n",
       " ' Iceland ',\n",
       " ' United States Minor Outlying Islands ',\n",
       " ' Peru ',\n",
       " ' Macedonia ',\n",
       " ' Belize ',\n",
       " ' Saint Barts ',\n",
       " ' Papua New Guinea ',\n",
       " ' Anguilla ',\n",
       " ' Thailand ',\n",
       " ' Costa Rica ',\n",
       " ' New Caledonia ',\n",
       " ' Germany ',\n",
       " ' East Timor ',\n",
       " ' Faroe Islands ',\n",
       " ' Togo ',\n",
       " ' India ',\n",
       " ' Hong Kong ',\n",
       " ' Qatar ',\n",
       " ' El Salvador ',\n",
       " ' Portugal ',\n",
       " ' Antarctica ',\n",
       " ' Dominica ',\n",
       " ' Panama ',\n",
       " ' Chile ',\n",
       " ' Slovenia ',\n",
       " ' Bonaire St Eustatius and Saba ',\n",
       " ' Crimea ',\n",
       " ' Cayman Islands ',\n",
       " ' South Korea ',\n",
       " ' Kiribati ',\n",
       " ' Brazil ',\n",
       " ' Barbados ',\n",
       " ' Nepal ',\n",
       " ' Maldives ',\n",
       " ' Saint Kitts and Nevis ',\n",
       " ' Congo ',\n",
       " ' Botswana ',\n",
       " ' Dominican Republic ',\n",
       " ' Guam ',\n",
       " ' Lesotho ',\n",
       " ' French Guiana ',\n",
       " ' Saint Lucia ',\n",
       " ' Switzerland ',\n",
       " ' Nigeria ',\n",
       " ' St Maarten ',\n",
       " ' Paraguay ',\n",
       " ' Puerto Rico ',\n",
       " ' Japan ',\n",
       " ' Zimbabwe ',\n",
       " ' Oman ',\n",
       " ' Ethiopia ',\n",
       " ' Estonia ',\n",
       " ' Turks Caicos Islands ',\n",
       " ' Slovakia ',\n",
       " ' Mexico ',\n",
       " ' Finland ',\n",
       " ' Mozambique ',\n",
       " ' Aruba ',\n",
       " ' China ',\n",
       " ' Tanzania ',\n",
       " ' Poland ',\n",
       " ' Netherlands ',\n",
       " ' Mauritania ',\n",
       " ' Venezuela ',\n",
       " ' Niger ',\n",
       " ' Jordan ',\n",
       " ' Grenada ',\n",
       " ' Belgium ',\n",
       " ' Mali ',\n",
       " ' Norway ',\n",
       " ' Denmark ',\n",
       " ' Uruguay ',\n",
       " ' Uzbekistan ',\n",
       " ' Falkland Islands Malvinas ',\n",
       " ' Liberia ',\n",
       " ' Colombia ',\n",
       " ' Cura ao ',\n",
       " ' Gabon ',\n",
       " ' Nicaragua ',\n",
       " ' Ukraine ',\n",
       " ' British Virgin Islands ',\n",
       " ' Reunion ',\n",
       " ' Myanmar ',\n",
       " ' Jersey ',\n",
       " ' ',\n",
       " ' Croatia ',\n",
       " ' Namibia ',\n",
       " ' Kenya ',\n",
       " ' Moldova ',\n",
       " ' Israel ',\n",
       " ' Singapore ',\n",
       " ' Guinea ',\n",
       " ' Romania ',\n",
       " ' Montserrat ',\n",
       " ' Saudi Arabia ',\n",
       " ' Belarus ',\n",
       " ' Palestinian Territory ',\n",
       " ' Vatican City ',\n",
       " ' Malta ',\n",
       " ' Burundi ',\n",
       " ' Kyrgyzstan ',\n",
       " ' Isle of Man ',\n",
       " ' Georgia ',\n",
       " ' French Polynesia ',\n",
       " ' San Marino ',\n",
       " ' Abkhazia Georgia ',\n",
       " ' Taiwan ',\n",
       " ' Algeria ',\n",
       " ' Lithuania ',\n",
       " ' Macau ',\n",
       " ' Ivory Coast ',\n",
       " ' Angola ',\n",
       " ' Monaco ',\n",
       " ' Equatorial Guinea ',\n",
       " ' Benin ',\n",
       " ' South Africa ']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewer_nationalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "There are weird trailing and leading spaces here, these need to be removed remove them and also remove ' '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Count NANs, Nulls, empty strings and zeros in the following 4 cells (in that order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_Address</th>\n",
       "      <th>Additional_Number_of_Scoring</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Reviewer_Nationality</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Review_Total_Negative_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews</th>\n",
       "      <th>Positive_Review</th>\n",
       "      <th>Review_Total_Positive_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>days_since_review</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hotel_Address  Additional_Number_of_Scoring  Review_Date  Average_Score  \\\n",
       "0              0                             0            0              0   \n",
       "\n",
       "   Hotel_Name  Reviewer_Nationality  Negative_Review  \\\n",
       "0           0                     0                0   \n",
       "\n",
       "   Review_Total_Negative_Word_Counts  Total_Number_of_Reviews  \\\n",
       "0                                  0                        0   \n",
       "\n",
       "   Positive_Review  Review_Total_Positive_Word_Counts  \\\n",
       "0                0                                  0   \n",
       "\n",
       "   Total_Number_of_Reviews_Reviewer_Has_Given  Reviewer_Score  Tags  \\\n",
       "0                                           0               0     0   \n",
       "\n",
       "   days_since_review  lat  lng  \n",
       "0                  0    0    0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "#https://stackoverflow.com/questions/44627386/how-to-find-count-of-null-and-nan-values-for-each-column-in-a-pyspark-dataframe\n",
    "df_hotel_reviews.select([count(when(isnan(c), c)).alias(c) for c in df_hotel_reviews.columns]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_Address</th>\n",
       "      <th>Additional_Number_of_Scoring</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Reviewer_Nationality</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Review_Total_Negative_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews</th>\n",
       "      <th>Positive_Review</th>\n",
       "      <th>Review_Total_Positive_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>days_since_review</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hotel_Address  Additional_Number_of_Scoring  Review_Date  Average_Score  \\\n",
       "0              0                             0            0              0   \n",
       "\n",
       "   Hotel_Name  Reviewer_Nationality  Negative_Review  \\\n",
       "0           0                     0                0   \n",
       "\n",
       "   Review_Total_Negative_Word_Counts  Total_Number_of_Reviews  \\\n",
       "0                                  0                        0   \n",
       "\n",
       "   Positive_Review  Review_Total_Positive_Word_Counts  \\\n",
       "0                0                                  0   \n",
       "\n",
       "   Total_Number_of_Reviews_Reviewer_Has_Given  Reviewer_Score  Tags  \\\n",
       "0                                           0               0     0   \n",
       "\n",
       "   days_since_review  lat  lng  \n",
       "0                  0    0    0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: this needs col(c)\n",
    "df_hotel_reviews.select([count(when(col(c).isNull(), c)).alias(c) for c in df_hotel_reviews.columns]).toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_Address</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Reviewer_Nationality</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Positive_Review</th>\n",
       "      <th>Tags</th>\n",
       "      <th>days_since_review</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>523</td>\n",
       "      <td>849</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hotel_Address  Review_Date  Hotel_Name  Reviewer_Nationality  \\\n",
       "0              0            0           0                   523   \n",
       "\n",
       "   Negative_Review  Positive_Review  Tags  days_since_review  lat  lng  \n",
       "0              849              183     0                  0    0    0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "@udf(returnType=StringType())\n",
    "def stripv(val):\n",
    "    return val.strip()\n",
    "\n",
    "string_columns = ['Hotel_Address', 'Review_Date', 'Hotel_Name', 'Reviewer_Nationality',\n",
    "                  'Negative_Review', 'Positive_Review', 'Tags', 'days_since_review', 'lat', 'lng']\n",
    "df_hotel_reviews.select([count(when(stripv(c)=='', c)).alias(c) for c in string_columns]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Additional_Number_of_Scoring</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Review_Total_Negative_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews</th>\n",
       "      <th>Review_Total_Positive_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127890</td>\n",
       "      <td>0</td>\n",
       "      <td>35946</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Additional_Number_of_Scoring  Average_Score  \\\n",
       "0                             0              0   \n",
       "\n",
       "   Review_Total_Negative_Word_Counts  Total_Number_of_Reviews  \\\n",
       "0                             127890                        0   \n",
       "\n",
       "   Review_Total_Positive_Word_Counts  \\\n",
       "0                              35946   \n",
       "\n",
       "   Total_Number_of_Reviews_Reviewer_Has_Given  Reviewer_Score  \n",
       "0                                           0               0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns = ['Additional_Number_of_Scoring', 'Average_Score', 'Review_Total_Negative_Word_Counts', 'Total_Number_of_Reviews',\n",
    "                   'Review_Total_Positive_Word_Counts', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'Reviewer_Score'  ]\n",
    "\n",
    "df_hotel_reviews.select([count(when(col(c)==0, c)).alias(c) for c in numeric_columns]).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "ACTION TO BE TAKEN:\n",
    "1. The issue with the trailing and leading spaces needs to be fixed. A strip udf will do the trick\n",
    "2. There are no nulls or nans. But there are empty strings -- these need to be replaced with nulls\n",
    "Note: Zeroes in numeric columns can be left alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Replace the existing columns\n",
    "for c in string_columns:\n",
    "    df_hotel_reviews= df_hotel_reviews.withColumn(c, stripv(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|Reviewer_Nationality|\n",
      "+--------------------+\n",
      "|Turks Caicos Islands|\n",
      "|              Russia|\n",
      "|            Paraguay|\n",
      "|            Anguilla|\n",
      "|               Yemen|\n",
      "|          St Maarten|\n",
      "|             Senegal|\n",
      "|              Sweden|\n",
      "|            Kiribati|\n",
      "|              Guyana|\n",
      "|              Jersey|\n",
      "|         Philippines|\n",
      "|             Eritrea|\n",
      "|            Djibouti|\n",
      "|            Malaysia|\n",
      "|           Singapore|\n",
      "|                Fiji|\n",
      "|              Turkey|\n",
      "|              Malawi|\n",
      "|                Iraq|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_hotel_reviews.select('Reviewer_Nationality').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Let's try to perform the same process as earlier -- let's get the list of distinct reviewer nationalities. We see that there are no trailing and leading spaces in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "list_of_reviewer_nationalities = df_hotel_reviews.select('Reviewer_Nationality').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "reviewer_nationalities = [row.__getitem__('Reviewer_Nationality') for row in list_of_reviewer_nationalities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Turks Caicos Islands',\n",
       " 'Russia',\n",
       " 'Paraguay',\n",
       " 'Anguilla',\n",
       " 'Yemen',\n",
       " 'St Maarten',\n",
       " 'Senegal',\n",
       " 'Sweden',\n",
       " 'Kiribati',\n",
       " 'Guyana',\n",
       " 'Jersey',\n",
       " 'Philippines',\n",
       " 'Eritrea',\n",
       " 'Djibouti',\n",
       " 'Malaysia',\n",
       " 'Singapore',\n",
       " 'Fiji',\n",
       " 'Turkey',\n",
       " 'Malawi',\n",
       " 'Iraq',\n",
       " 'Germany',\n",
       " 'Northern Mariana Islands',\n",
       " 'Comoros',\n",
       " 'Crimea',\n",
       " 'Cambodia',\n",
       " 'Afghanistan',\n",
       " 'Rwanda',\n",
       " 'Jordan',\n",
       " 'Maldives',\n",
       " 'Ivory Coast',\n",
       " 'Sudan',\n",
       " 'Palau',\n",
       " 'France',\n",
       " 'Greece',\n",
       " 'Kosovo',\n",
       " 'Svalbard Jan Mayen',\n",
       " 'Sri Lanka',\n",
       " 'Montserrat',\n",
       " 'Taiwan',\n",
       " 'British Virgin Islands',\n",
       " 'Dominica',\n",
       " 'Togo',\n",
       " 'Algeria',\n",
       " 'Equatorial Guinea',\n",
       " 'Slovakia',\n",
       " 'Macau',\n",
       " 'Reunion',\n",
       " 'Argentina',\n",
       " 'Belgium',\n",
       " 'Angola',\n",
       " 'San Marino',\n",
       " 'East Timor',\n",
       " 'Qatar',\n",
       " 'Ecuador',\n",
       " 'Lesotho',\n",
       " 'Albania',\n",
       " 'Madagascar',\n",
       " 'Finland',\n",
       " 'New Caledonia',\n",
       " 'Ghana',\n",
       " 'Nicaragua',\n",
       " 'Myanmar',\n",
       " 'Guernsey',\n",
       " 'Peru',\n",
       " 'Sierra Leone',\n",
       " 'Benin',\n",
       " 'India',\n",
       " 'China',\n",
       " 'Bahamas',\n",
       " 'Belarus',\n",
       " 'Malta',\n",
       " 'Kuwait',\n",
       " 'American Samoa',\n",
       " 'Central Africa Republic',\n",
       " 'Somalia',\n",
       " 'Tuvalu',\n",
       " 'Palestinian Territory',\n",
       " 'Chile',\n",
       " 'Puerto Rico',\n",
       " 'Tajikistan',\n",
       " 'Martinique',\n",
       " 'Cocos K I',\n",
       " 'Cayman Islands',\n",
       " 'Isle of Man',\n",
       " 'Croatia',\n",
       " 'Bonaire St Eustatius and Saba',\n",
       " 'Burundi',\n",
       " 'Nigeria',\n",
       " 'Andorra',\n",
       " 'Bolivia',\n",
       " 'Gabon',\n",
       " 'Falkland Islands Malvinas',\n",
       " 'Italy',\n",
       " 'Cura ao',\n",
       " 'Suriname',\n",
       " 'Lithuania',\n",
       " 'Norway',\n",
       " 'Turkmenistan',\n",
       " 'Spain',\n",
       " 'Mauritania',\n",
       " 'Guadeloupe',\n",
       " 'Denmark',\n",
       " 'Abkhazia Georgia',\n",
       " 'Niger',\n",
       " 'Bangladesh',\n",
       " 'Barbados',\n",
       " 'Iran',\n",
       " 'Ireland',\n",
       " 'Liechtenstein',\n",
       " 'Congo',\n",
       " 'Thailand',\n",
       " 'Laos',\n",
       " 'Swaziland',\n",
       " 'Democratic Republic of the Congo',\n",
       " 'Bhutan',\n",
       " 'Morocco',\n",
       " 'Monaco',\n",
       " 'Panama',\n",
       " 'Cape Verde',\n",
       " 'Hong Kong',\n",
       " 'Ukraine',\n",
       " 'Venezuela',\n",
       " 'Israel',\n",
       " 'Iceland',\n",
       " 'Antarctica',\n",
       " 'Saint Kitts and Nevis',\n",
       " 'Oman',\n",
       " 'French Polynesia',\n",
       " 'Saint Barts',\n",
       " 'United States of America',\n",
       " 'South Korea',\n",
       " 'Gibraltar',\n",
       " 'Cyprus',\n",
       " 'Uruguay',\n",
       " 'Mexico',\n",
       " 'Aruba',\n",
       " 'Estonia',\n",
       " 'Montenegro',\n",
       " 'Zimbabwe',\n",
       " 'Georgia',\n",
       " 'Indonesia',\n",
       " 'Guatemala',\n",
       " 'Mongolia',\n",
       " 'Guam',\n",
       " 'Azerbaijan',\n",
       " 'Libya',\n",
       " 'Grenada',\n",
       " 'Armenia',\n",
       " 'Tunisia',\n",
       " 'Liberia',\n",
       " 'Honduras',\n",
       " 'Syria',\n",
       " 'Trinidad and Tobago',\n",
       " 'Saudi Arabia',\n",
       " 'Uganda',\n",
       " 'Wallis and Futuna',\n",
       " 'Saint Vincent Grenadines',\n",
       " 'French Guiana',\n",
       " 'Namibia',\n",
       " 'Switzerland',\n",
       " 'Zambia',\n",
       " 'Ethiopia',\n",
       " 'Antigua Barbuda',\n",
       " 'Latvia',\n",
       " 'Jamaica',\n",
       " 'United Arab Emirates',\n",
       " 'Brunei',\n",
       " 'South Sudan',\n",
       " 'U S Virgin Islands',\n",
       " 'Saint Martin',\n",
       " 'Saint Lucia',\n",
       " 'Guinea',\n",
       " 'Canada',\n",
       " 'Seychelles',\n",
       " 'Macedonia',\n",
       " 'Uzbekistan',\n",
       " 'Faroe Islands',\n",
       " 'Kyrgyzstan',\n",
       " 'Samoa',\n",
       " 'Czech Republic',\n",
       " 'Mozambique',\n",
       " 'Cook Islands',\n",
       " 'Brazil',\n",
       " 'Belize',\n",
       " 'Kenya',\n",
       " 'Gambia',\n",
       " 'Lebanon',\n",
       " 'Slovenia',\n",
       " 'St Pierre and Miquelon',\n",
       " 'Dominican Republic',\n",
       " 'Japan',\n",
       " 'Botswana',\n",
       " 'Tanzania',\n",
       " 'Luxembourg',\n",
       " 'New Zealand',\n",
       " 'United States Minor Outlying Islands',\n",
       " '',\n",
       " 'Bosnia and Herzegovina',\n",
       " 'Haiti',\n",
       " 'Poland',\n",
       " 'Portugal',\n",
       " 'Australia',\n",
       " 'Papua New Guinea',\n",
       " 'Cameroon',\n",
       " 'Romania',\n",
       " 'Bulgaria',\n",
       " 'Austria',\n",
       " 'Nepal',\n",
       " 'Egypt',\n",
       " 'Costa Rica',\n",
       " 'Kazakhstan',\n",
       " 'El Salvador',\n",
       " 'Serbia',\n",
       " 'South Africa',\n",
       " 'Bermuda',\n",
       " 'Bahrain',\n",
       " 'Colombia',\n",
       " 'Hungary',\n",
       " 'Pakistan',\n",
       " 'Vanuatu',\n",
       " 'Vatican City',\n",
       " 'Mauritius',\n",
       " 'United Kingdom',\n",
       " 'Moldova',\n",
       " 'Vietnam',\n",
       " 'Netherlands',\n",
       " 'Mali']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewer_nationalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def blank_as_null(val):\n",
    "    return when(col(val) != \"\", col(val)).otherwise(None)\n",
    "\n",
    "for c in string_columns:\n",
    "    df_hotel_reviews= df_hotel_reviews.withColumn(c, blank_as_null(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Count empty strings and nulls again to see if this operation worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1520.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 66.0 failed 1 times, most recent failure: Lost task 0.0 in stage 66.0 (TID 1291, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 345, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 141, in dump_stream\n    for obj in iterator:\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 334, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 85, in <lambda>\n    return lambda *a: f(*a)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-41-2468b537e4c9>\", line 4, in stripv\nAttributeError: 'NoneType' object has no attribute 'strip'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.agg_doAggregateWithoutKey_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:299)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3257)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3254)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3364)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3363)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3254)\n\tat sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 345, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 141, in dump_stream\n    for obj in iterator:\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 334, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 85, in <lambda>\n    return lambda *a: f(*a)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-41-2468b537e4c9>\", line 4, in stripv\nAttributeError: 'NoneType' object has no attribute 'strip'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.agg_doAggregateWithoutKey_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-678a3069e2c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m string_columns = ['Hotel_Address', 'Review_Date', 'Hotel_Name', 'Reviewer_Nationality',\n\u001b[1;32m      2\u001b[0m                   'Negative_Review', 'Positive_Review', 'Tags', 'days_since_review', 'lat', 'lng']\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_hotel_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstripv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m         \u001b[0;31m# Below is toPandas without Arrow optimization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2142\u001b[0;31m         \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \"\"\"\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1520.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 66.0 failed 1 times, most recent failure: Lost task 0.0 in stage 66.0 (TID 1291, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 345, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 141, in dump_stream\n    for obj in iterator:\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 334, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 85, in <lambda>\n    return lambda *a: f(*a)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-41-2468b537e4c9>\", line 4, in stripv\nAttributeError: 'NoneType' object has no attribute 'strip'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.agg_doAggregateWithoutKey_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:299)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3257)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3254)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3364)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3363)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3254)\n\tat sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 345, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 141, in dump_stream\n    for obj in iterator:\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 334, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 85, in <lambda>\n    return lambda *a: f(*a)\n  File \"/opt/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-41-2468b537e4c9>\", line 4, in stripv\nAttributeError: 'NoneType' object has no attribute 'strip'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.agg_doAggregateWithoutKey_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "string_columns = ['Hotel_Address', 'Review_Date', 'Hotel_Name', 'Reviewer_Nationality',\n",
    "                  'Negative_Review', 'Positive_Review', 'Tags', 'days_since_review', 'lat', 'lng']\n",
    "df_hotel_reviews.select([count(when(stripv(c)=='', c)).alias(c) for c in string_columns]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "There is a None, so the operation was successfully completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
