{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jsonlines\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/9a/ab96291470e305504aa4b7a2e0ec132e930da89eb3ca7a82fbe03167c131/jsonlines-1.2.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from jsonlines) (1.11.0)\n",
      "Installing collected packages: jsonlines\n",
      "Successfully installed jsonlines-1.2.0\n",
      "Collecting https://github.com/elyase/geotext/archive/master.zip\n",
      "  Downloading https://github.com/elyase/geotext/archive/master.zip\n",
      "\u001b[K     / 4.3MB 96.8MB/s    / 81kB 299kB/s\n",
      "Building wheels for collected packages: geotext\n",
      "  Running setup.py bdist_wheel for geotext ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-xrga8q69/wheels/f5/e3/84/31638877059a434d8601a764fc7565f2a9f7b6fb327085191e\n",
      "Successfully built geotext\n",
      "Installing collected packages: geotext\n",
      "Successfully installed geotext-0.3.0\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (4.11.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install jsonlines\n",
    "! pip install https://github.com/elyase/geotext/archive/master.zip\n",
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jsonlines'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-91379ea9102c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjsonlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgeotext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGeoText\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jsonlines'"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import json\n",
    "import jsonlines\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from geotext import GeoText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The data has a lot of issues. It cannot be directly read by Spark (you get a 'corrupted record') as there is a lot of nesting. Similarly, you get an error when you try to read the data with pandas. Python's native json library and the jsonlines module cannot read it because it contains single quotes rather than double quotes (json requires double quotes). The solution is to read the data line by line, use the ast library to convert single quotes to double quotes, remove trailing commas, and dump it to valid json. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The original file was called places.clean.json, I changed the name to places.original.json because it really isn't 'clean' yet as far as my requirements are concerned.\n",
    "\n",
    "Number of records in places.original.json (places.clean.json): 3114353\n",
    "\n",
    "Sample records:\n",
    "\n",
    "{\"name\": \"Diamond Valley Lake Marina\", \"price\": null, \"address\": [\"2615 Angler Ave\", \"Hemet, CA 92545\"], \"hours\": [[\"Monday\", [[\"6:30 am--4:15 pm\"]]], [\"Tuesday\", [[\"6:30 am--4:15 pm\"]]], [\"Wednesday\", [[\"6:30 am--4:15 pm\"]], 1], [\"Thursday\", [[\"6:30 am--4:15 pm\"]]], [\"Friday\", [[\"6:30 am--4:15 pm\"]]], [\"Saturday\", [[\"6:30 am--4:15 pm\"]]], [\"Sunday\", [[\"6:30 am--4:15 pm\"]]]], \"phone\": \"(951) 926-7201\", \"closed\": false, \"gPlusPlaceId\": \"104699454385822125632\", \"gps\": [33.703804, -117.003209]}\n",
    "\n",
    "{\"name\": \"Blue Ribbon Cleaners\", \"price\": null, \"address\": [\"Parole\", \"Annapolis, MD\"], \"hours\": null, \"phone\": \"(410) 266-6123\", \"closed\": false, \"gPlusPlaceId\": \"103054478949000078829\", \"gps\": [38.979759, -76.547538]}\n",
    "\n",
    "{\"name\": \"Portofino\", \"price\": null, \"address\": [\"\\u0443\\u043b. \\u0422\\u0443\\u0442\\u0430\\u0435\\u0432\\u0430, 1\", \"Nazran, Ingushetia, Russia\", \"366720\"], \"hours\": [[\"Monday\", [[\"9:30 am--9:00 pm\"]]], [\"Tuesday\", [[\"9:30 am--9:00 pm\"]]], [\"Wednesday\", [[\"9:30 am--9:00 pm\"]], 1], [\"Thursday\", [[\"9:30 am--9:00 pm\"]]], [\"Friday\", [[\"9:30 am--9:00 pm\"]]], [\"Saturday\", [[\"9:30 am--9:00 pm\"]]], [\"Sunday\", [[\"9:30 am--9:00 pm\"]]]], \"phone\": \"8 (963) 173-38-38\", \"closed\": false, \"gPlusPlaceId\": \"109810290098030327104\", \"gps\": [43.22776, 44.762726]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Steps\n",
    "1. Read the original json file which contains corrupted json. \n",
    "2. We don't need all the data. So a check is made to see if the country in the record is one of 6 countries (which are the places with hotels in them in the other file, 515k_reviews). Of course, we don't have a field for the country, so this is just a substring search after converting the strings to lower case. The next steps take place only if the business is located in one of the 6 countries.\n",
    "3. Use the literal_eval function in the builtin module ast (which is generally used to process tree data) to convert single quotes to double quotes. This will also remove trailing commas. Note that ast.literal_eval returns a dictionary (it interprets the JSON line as a dict), which by default uses double quotes. It also removes the unicode indicator u''.\n",
    "4. The address field is a json array. This needs to be converted into one field.\n",
    "5. As an additional step, I get the city and country from the address using a simple NER library. A more complex method will work better, but this is what I'm using for now.\n",
    "6. The gps, another json array, is split into two new fields: latitude and longitude.\n",
    "7. Finally, the most complex field, hours, needs to be handled. This contains either None, or a list of lists, each of which has a day and another list of lists. This needs to be flattened -- I do this by using a generator. In the final resulting output, I add 7 new fields for the opening hours of each day: MondayHours, TuesdayHours and so on.\n",
    "8. Write the results back into a new jsonlines file which contains valid JSON.\n",
    "\n",
    "Note: this file does not contains any of the intermediate steps. The explore_13lines_google_places.ipynb file shows the intermediate steps I used while constructing the program. The program itself is also present in clean_google_places.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def flatten(day_hours_list):\n",
    "    \"\"\" Generator which flattens a list of lists recursively by yielding strings and ints/floats\n",
    "    directly and recursively calling the generator func if it's an iterable \"\"\"\n",
    "    for el in day_hours_list:\n",
    "        if isinstance(el, collections.Iterable) and not isinstance(el, (str, bytes)):\n",
    "            yield from flatten(el)\n",
    "        else:\n",
    "            yield el\n",
    "\n",
    "def process_hours(opening_hours):\n",
    "    \"\"\" Takes a Json array of opening_hours in the following form (None if not present), and\n",
    "    returns a dictionary containing days as keys and opening hours as string values\n",
    "    [['Monday', [['6:30 am--4:15 pm']]],\n",
    "    ['Tuesday', [['6:30 am--4:15 pm']]],\n",
    "    ['Wednesday', [['6:30 am--4:15 pm']], 1],\n",
    "    ['Thursday', [['6:30 am--4:15 pm']]],\n",
    "    ['Friday', [['6:30 am--4:15 pm']]],\n",
    "    ['Saturday', [['6:30 am--4:15 pm']]],\n",
    "    ['Sunday', [['6:30 am--4:15 pm']]]] \"\"\"\n",
    "    day_keys = ['MondayHours', 'TuesdayHours', 'WednesdayHours', 'ThursdayHours',\n",
    "            'FridayHours', 'SaturdayHours', 'SundayHours']\n",
    "    if opening_hours is None:\n",
    "        # Return None for each day\n",
    "        return {k:None for k in day_keys}\n",
    "    return_dict = dict()\n",
    "    for day_hours in opening_hours:\n",
    "        # day_hours[0] is the day, [1] is the list of lists\n",
    "        return_dict[day_hours[0]+'Hours'] = next(flatten(day_hours[1]))\n",
    "        \n",
    "    return return_dict   \n",
    "\n",
    "countries = ['france', 'italy', 'spain', 'united kingdom', 'austria', 'netherlands']\n",
    "with jsonlines.open('../Data/Cleaned/google_places_cleaned.jsonl', mode='w') as writer:\n",
    "    with open('../Data/Original/places.original.json', 'r') as testfile:\n",
    "        # fields: 'name', 'price', 'address', 'hours', 'phone', 'closed', 'gPlusPlaceId', 'gps'\n",
    "        for line in tqdm(testfile):\n",
    "            normalised_dict = ast.literal_eval(line)\n",
    "            print(normalised_dict.keys())\n",
    "            joined_address = ', '.join(normalised_dict.get('address'))\n",
    "            if any(country in joined_address.lower() for country in countries):\n",
    "                # Country found in the list, find which country it is.\n",
    "                # GeoText module only detects the city/country if it is capitalised\n",
    "                geo_address = GeoText(joined_address.title())\n",
    "                try:\n",
    "                    matching_country = geo_address.countries[0]\n",
    "                except IndexError:\n",
    "                    matching_country = [country for country in countries if country in joined_address.lower()][0].title()\n",
    "                try:\n",
    "                    #If it matches 2 cities for some reason, take the one closer to the end of the string.\n",
    "                    matching_city = geo_address.cities[-1]\n",
    "                except IndexError:\n",
    "                    matching_city = None\n",
    "                normalised_dict['country'] = matching_country\n",
    "                normalised_dict['city'] = matching_city\n",
    "                normalised_dict['latitude'] = normalised_dict.get('gps')[0]\n",
    "                normalised_dict['longitude'] = normalised_dict.get('gps')[1]\n",
    "                opening_hours_dict = process_hours(normalised_dict.get('hours'))\n",
    "                # Add the new keys (Monday, Tuesday, ...)\n",
    "                normalised_dict.update(opening_hours_dict)\n",
    "                print(normalised_dict.keys())\n",
    "                del normalised_dict['closed']\n",
    "                del normalised_dict['gps']\n",
    "                del normalised_dict['hours']\n",
    "                \n",
    "                # Write to output jsonl file\n",
    "                writer.write(normalised_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The resulting file (google_places_cleaned.jsonl) has 464,906 records in jsonlines format."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
